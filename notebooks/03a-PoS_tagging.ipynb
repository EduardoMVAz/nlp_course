{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging\n",
    "\n",
    "Part-of-speech tagging is the task of identifying the grammatical classes of words in a sentence. In this class, we will use the concept of n-grams to help us automatically identify grammatical classes.\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "In the sentences below, identify the *nouns*, *verbs*, *adjectives*, and *adverbs*:\n",
    "\n",
    "1. Today I woke up serenely and saw that it was a beautiful and calm day.\n",
    "1. The mutation of fungi is capable of controlling people's minds!\n",
    "1. Every day, the morning Sun comes and challenges us!\n",
    "1. It is no use trying to make an automatic system that does something we do not understand the result of!\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "There are many words that always have the same PoS definition - maybe the word Sun, for example, is always a noun. However, there are others that can change their meaning according to the context, such as \"house\": \"I live in a house\" (noun), versus \"I like house music\" (adjective), versus \"The museums house a collection of ancient artifacts\" (verb).\n",
    "\n",
    "Because of that, it is important to use context to determine the\n",
    "\n",
    "Recall that our language model context model was:\n",
    "\n",
    "$$\n",
    "ùëÉ(ùë§_ùëõ‚à£ùë§_{ùëõ‚àí1}, w_{n-2}, \\cdots, w_{n-L})\n",
    "$$\n",
    "\n",
    "Now, we can make a small change and use:\n",
    "\n",
    "$$\n",
    "ùëÉ(\\text{tag}‚à£w_n, ùë§_{ùëõ‚àí1}, w_{n-2}, \\cdots, w_{n-L})\n",
    "$$\n",
    "\n",
    "Similarly to the language models, we can use a fallback n-gram strategy to make a reasonable model. But, first, we will need to download a corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\emend\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A corpus is a collection of texts. The [Brown corpus](https://en.wikipedia.org/wiki/Brown_Corpus) has many phrases, with categories and word-level tags for part-of-speech. This was done manually by a team of brave taggers. Here are some highlights on how to use the [Brown corpus in NLTK](https://www.nltk.org/book/ch02.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a list of categories in the Brown corpus\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Too', 'often', 'a', 'beginning', 'bodybuilder', 'has', 'to', 'do', 'his', 'training', 'secretly', 'either', 'because', 'his', 'parents', \"don't\", 'want', 'sonny-boy', 'to', '``', 'lift', 'all', 'those', 'old', 'barbell', 'things', \"''\", 'because', '``', \"you'll\", 'stunt', 'your', 'growth', \"''\", 'or', 'because', 'childish', 'taunts', 'from', 'his', 'schoolmates', ',', 'like', '``', 'Hey', 'lookit', 'Mr.', 'America', ';', ';'], ['whaddya', 'gonna', 'do', 'with', 'all', 'those', 'muscles', '(', 'of', 'which', 'he', 'has', 'none', 'at', 'the', 'time', ')', \"''\", '?', '?'], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a list of sentences in a category:\n",
    "brown.sents(categories='hobbies')\n",
    "# Each sentence is a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Too', 'QL'), ('often', 'RB'), ('a', 'AT'), ('beginning', 'VBG'), ('bodybuilder', 'NN'), ('has', 'HVZ'), ('to', 'TO'), ('do', 'DO'), ('his', 'PP$'), ('training', 'NN'), ('secretly', 'RB'), ('either', 'CC'), ('because', 'CS'), ('his', 'PP$'), ('parents', 'NNS'), (\"don't\", 'DO*'), ('want', 'VB'), ('sonny-boy', 'NN'), ('to', 'TO'), ('``', '``'), ('lift', 'VB'), ('all', 'ABN'), ('those', 'DTS'), ('old', 'JJ'), ('barbell', 'NN'), ('things', 'NNS'), (\"''\", \"''\"), ('because', 'CS'), ('``', '``'), (\"you'll\", 'PPSS+MD'), ('stunt', 'VB'), ('your', 'PP$'), ('growth', 'NN'), (\"''\", \"''\"), ('or', 'CC'), ('because', 'CS'), ('childish', 'JJ'), ('taunts', 'NNS'), ('from', 'IN'), ('his', 'PP$'), ('schoolmates', 'NNS'), (',', ','), ('like', 'CS'), ('``', '``'), ('Hey', 'UH'), ('lookit', 'VB+IN'), ('Mr.', 'NP'), ('America', 'NP'), (';', '.'), (';', '.')], [('whaddya', 'WDT+BER+PP'), ('gonna', 'VBG+TO'), ('do', 'DO'), ('with', 'IN'), ('all', 'ABN'), ('those', 'DTS'), ('muscles', 'NNS'), ('(', '('), ('of', 'IN'), ('which', 'WDT'), ('he', 'PPS'), ('has', 'HVZ'), ('none', 'PN'), ('at', 'IN'), ('the', 'AT'), ('time', 'NN'), (')', ')'), (\"''\", \"''\"), ('?', '.'), ('?', '.')], ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a list of *tagged* sentences in a category:\n",
    "brown.tagged_sents(categories='hobbies')\n",
    "# You can find the meaning of the tags by looking at the Wikipedia article: https://en.wikipedia.org/wiki/Brown_Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**\n",
    "\n",
    "Make code to count the proportion of each tag throughout the corpus. If you finish this too quickly, subdivide your count by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def create_proportion_dict_for_taggs_in_speech(speech_list: list):\n",
    "    tags = defaultdict(int)\n",
    "\n",
    "    for phrase in speech_list:\n",
    "        for _, tag in phrase:\n",
    "            tags[tag] += 1\n",
    "\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = create_proportion_dict_for_taggs_in_speech(brown.tagged_sents(categories='hobbies'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN             0.151375\n",
       "IN             0.104329\n",
       "AT             0.084352\n",
       "NNS            0.062214\n",
       "JJ             0.059299\n",
       "                 ...   \n",
       "PP$-TL         0.000012\n",
       "BE-HL          0.000012\n",
       "DTS-HL         0.000012\n",
       "DO-HL          0.000012\n",
       "FW-IN+NN-TL    0.000012\n",
       "Length: 209, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series(tags).sort_values(ascending=False)\n",
    "df / df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Suppose we have no idea how to choose a PoS tag for any word. Our best guess is to pick one. For example, in the code below, we tag all words as qualifiers (QL). As we can see from the evaluation process, this is not a very accurate method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Too', 'NN'), ('often', 'NN'), ('a', 'NN'), ('beginning', 'NN'), ('bodybuilder', 'NN'), ('has', 'NN'), ('to', 'NN'), ('do', 'NN'), ('his', 'NN'), ('training', 'NN'), ('secretly', 'NN'), ('either', 'NN'), ('because', 'NN'), ('his', 'NN'), ('parents', 'NN'), (\"don't\", 'NN'), ('want', 'NN'), ('sonny-boy', 'NN'), ('to', 'NN'), ('``', 'NN'), ('lift', 'NN'), ('all', 'NN'), ('those', 'NN'), ('old', 'NN'), ('barbell', 'NN'), ('things', 'NN'), (\"''\", 'NN'), ('because', 'NN'), ('``', 'NN'), (\"you'll\", 'NN'), ('stunt', 'NN'), ('your', 'NN'), ('growth', 'NN'), (\"''\", 'NN'), ('or', 'NN'), ('because', 'NN'), ('childish', 'NN'), ('taunts', 'NN'), ('from', 'NN'), ('his', 'NN'), ('schoolmates', 'NN'), (',', 'NN'), ('like', 'NN'), ('``', 'NN'), ('Hey', 'NN'), ('lookit', 'NN'), ('Mr.', 'NN'), ('America', 'NN'), (';', 'NN'), (';', 'NN')]\n",
      "[('Too', 'QL'), ('often', 'RB'), ('a', 'AT'), ('beginning', 'VBG'), ('bodybuilder', 'NN'), ('has', 'HVZ'), ('to', 'TO'), ('do', 'DO'), ('his', 'PP$'), ('training', 'NN'), ('secretly', 'RB'), ('either', 'CC'), ('because', 'CS'), ('his', 'PP$'), ('parents', 'NNS'), (\"don't\", 'DO*'), ('want', 'VB'), ('sonny-boy', 'NN'), ('to', 'TO'), ('``', '``'), ('lift', 'VB'), ('all', 'ABN'), ('those', 'DTS'), ('old', 'JJ'), ('barbell', 'NN'), ('things', 'NNS'), (\"''\", \"''\"), ('because', 'CS'), ('``', '``'), (\"you'll\", 'PPSS+MD'), ('stunt', 'VB'), ('your', 'PP$'), ('growth', 'NN'), (\"''\", \"''\"), ('or', 'CC'), ('because', 'CS'), ('childish', 'JJ'), ('taunts', 'NNS'), ('from', 'IN'), ('his', 'PP$'), ('schoolmates', 'NNS'), (',', ','), ('like', 'CS'), ('``', '``'), ('Hey', 'UH'), ('lookit', 'VB+IN'), ('Mr.', 'NP'), ('America', 'NP'), (';', '.'), (';', '.')]\n",
      "Accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "default_tagger = DefaultTagger('NN')\n",
    "sentence = brown.sents(categories='hobbies')[0]\n",
    "sentence_tagged = default_tagger.tag(sentence)\n",
    "sentence_ground_truth = brown.tagged_sents(categories='hobbies')[0]\n",
    "print(sentence_tagged)\n",
    "print(sentence_ground_truth)\n",
    "accuracy = default_tagger.accuracy([sentence_ground_truth])\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change the evaluation process above to calculate accuracy over all the 'editorial' category of the Brown corpus\n",
    "1. Change the default tag to the most common tag you have found in Exercise 2. What is your change in accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "NLTK also comes with Unigram taggers. These taggers use $L=0$ in the context, that is, they always tag a word in the same way.\n",
    "\n",
    "The Unigram taggers requires training data. In the example below, we use the tagged sentences from the \"hobbies\" category for that.\n",
    "\n",
    "Of course, there is a change that the word we want does not appear in the training data. In this case, what is the best alternative? Well, we can choose the most common tag in the dataset - which is what we had been doing with the default tagger. This strategy is called \"backoff\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7948460921559539 +- 0.13081129038561165\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.tag import UnigramTagger\n",
    "unigram_tagger = UnigramTagger(brown.tagged_sents(categories='hobbies'), backoff=default_tagger)\n",
    "accuracies = []\n",
    "for sentence_ground_truth in brown.tagged_sents(categories=\"adventure\"):\n",
    "    accuracy = unigram_tagger.accuracy([sentence_ground_truth])\n",
    "    accuracies.append(accuracy)\n",
    "print(f'Accuracy: {np.mean(accuracies)} +- {np.std(accuracies)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Unigram tagger in the 'hobbies' category. Then, test it in sentences of each category.\n",
    "\n",
    "1. What do you observe in the results?\n",
    "1. Does this phenomenon happen for any category chosen for training?\n",
    "1. Make an experiment to find out if this phenomenon is due to train and test being from the same category, of if it is due to they containing strictly the same sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "We can also use n-gram taggers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8098462639586184 +- 0.13313355985052241\n"
     ]
    }
   ],
   "source": [
    "from nltk import NgramTagger\n",
    "bigram_tagger = NgramTagger(n=2, train=brown.tagged_sents(categories='hobbies'), backoff=unigram_tagger)\n",
    "accuracies = []\n",
    "for sentence_ground_truth in brown.tagged_sents(categories=\"adventure\"):\n",
    "    accuracy = bigram_tagger.accuracy([sentence_ground_truth])\n",
    "    accuracies.append(accuracy)\n",
    "print(f'Accuracy: {np.mean(accuracies)} +- {np.std(accuracies)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evaluate the bigram tagger\n",
    "1. Make a function that receives a value of $n$ and a training set as parameters, and returns a PoS tagger with n-gram taggers for that $n$ with a successive backoff option that\n",
    "1. Make a figure showing how the accuracy increases in the Brown corpus when $n$ is increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "One measure of wordiness in a text is the lexical density. Lexical Density is a concept that comes from the idea that nouns and verbs convey meaning, and other words are only auxiliary. The Lexical Density is calculated for a sentence as the number of nouns and verbs, divided by the total number of words in the sentence.\n",
    "\n",
    "Make a function that receives a sentence (and possibly a PoS tagger) as inputs and returns the sentence's lexical density.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dan Morgan told himself he would forget Ann Turner .\n",
      "The lexical density of the sentence is: 50.00%\n",
      "\n",
      "He was well rid of her .\n",
      "The lexical density of the sentence is: 14.29%\n",
      "\n",
      "He certainly didn't want a wife who was fickle as Ann .\n",
      "The lexical density of the sentence is: 33.33%\n",
      "\n",
      "If he had married her , he'd have been asking for trouble .\n",
      "The lexical density of the sentence is: 30.77%\n",
      "\n",
      "But all of this was rationalization .\n",
      "The lexical density of the sentence is: 14.29%\n",
      "\n",
      "Sometimes he woke up in the middle of the night thinking of Ann , and then could not get back to sleep .\n",
      "The lexical density of the sentence is: 26.09%\n",
      "\n",
      "His plans and dreams had revolved around her so much and for so long that now he felt as if he had nothing .\n",
      "The lexical density of the sentence is: 16.67%\n",
      "\n",
      "The easiest thing would be to sell out to Al Budd and leave the country , but there was a stubborn streak in him that wouldn't allow it .\n",
      "The lexical density of the sentence is: 34.48%\n",
      "\n",
      "The best antidote for the bitterness and disappointment that poisoned him was hard work .\n",
      "The lexical density of the sentence is: 33.33%\n",
      "\n",
      "He found that if he was tired enough at night , he went to sleep simply because he was too exhausted to stay awake .\n",
      "The lexical density of the sentence is: 32.00%\n",
      "\n",
      "Each day he found himself thinking less often of Ann ; ;\n",
      "The lexical density of the sentence is: 33.33%\n",
      "\n",
      "each day the hurt was a little duller , a little less poignant .\n",
      "The lexical density of the sentence is: 28.57%\n",
      "\n",
      "He had plenty of work to do .\n",
      "The lexical density of the sentence is: 25.00%\n",
      "\n",
      "Because the summer was unusually dry and hot , the spring produced a smaller stream than in ordinary years .\n",
      "The lexical density of the sentence is: 30.00%\n",
      "\n",
      "The grass in the meadows came fast , now that the warm weather was here .\n",
      "The lexical density of the sentence is: 25.00%\n",
      "\n",
      "He could not afford to lose a drop of the precious water , so he spent most of his waking hours along the ditches in his meadows .\n",
      "The lexical density of the sentence is: 28.57%\n",
      "\n",
      "He had no idea how much time Budd would give him .\n",
      "The lexical density of the sentence is: 33.33%\n",
      "\n",
      "In any case , he had no intention of being caught asleep , so he carried his revolver in its holster on his hip and he took his Winchester with him and leaned it against the fence .\n",
      "The lexical density of the sentence is: 28.95%\n",
      "\n",
      "He stopped every few minutes and leaned on his shovel as he studied the horizon , but nothing happened , each day dragging out with monotonous calm .\n",
      "The lexical density of the sentence is: 39.29%\n",
      "\n",
      "When , in late afternoon on the last day in June , he saw two people top the ridge to the south and walk toward the house , he quit work immediately and strode to his rifle .\n",
      "The lexical density of the sentence is: 31.58%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentence_lexical_density(sentence: list, tagger: NgramTagger):\n",
    "    tagged_sentence = tagger.tag(sentence)\n",
    "    nouns_and_verbs = len([tag[1] for tag in tagged_sentence if tag[1] in ['NN', 'NNA', 'NNC', 'NNS', 'NNP', 'NNPC', 'VB', 'VBA', 'VBD', 'VBG', 'VBN', 'VBZ']])\n",
    "    return f'The lexical density of the sentence is: {nouns_and_verbs / len(tagged_sentence) * 100:.2f}%'\n",
    "\n",
    "for i in range(20):\n",
    "    print(\" \".join([sentence for sentence in brown.sents(categories=\"adventure\")[i]]))\n",
    "    print(sentence_lexical_density(brown.sents(categories=\"adventure\")[i], bigram_tagger))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
